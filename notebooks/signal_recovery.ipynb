{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pierreo\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the GP cross validation\n",
    "from problems import get_synthetic_problem\n",
    "import torch\n",
    "from search.trust_region import (\n",
    "    restart,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from search.utils import eigendecompose_laplacian\n",
    "from search.models import initialize_model\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm._tqdm import tqdm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment to carry out:\n",
    "- Sample graph\n",
    "- Take eigendecomposition\n",
    "- Take a eigenvalue\n",
    "- Sample nodes\n",
    "- Reconstruct signals and compare real one with different modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 400\n",
    "base_problem = get_synthetic_problem(\n",
    "    \"test_function\", \n",
    "    n=n, \n",
    "    seed=2,\n",
    "    problem_kwargs={\n",
    "        \"log\": False, \n",
    "        \"random_graph_type\": \"grid\",\n",
    "        \"m\": 1,\n",
    "        \"n\": n,\n",
    "        \"test_function\": \"sphere\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "X_train = torch.empty(0,1)\n",
    "Y_train = torch.empty(0,1)\n",
    "base_model, base_mll, based_cached_eigenbasis = initialize_model(\n",
    "                train_X=X_train,\n",
    "                train_Y=Y_train,\n",
    "                context_graph=base_problem.context_graph,\n",
    "                covar_type=\"diffusion\",\n",
    "                covar_kwargs = {\n",
    "                    \"order\": 1,\n",
    "                     },\n",
    "                fit_model=False,\n",
    "                ard=True,\n",
    "                use_fixed_noise=False,\n",
    "                use_saas_map=False\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_result(base_problem, base_model, prop_data=0.5, mc_samples=5, n_eigenvalue=10):\n",
    "    r = torch.arange(1,len(base_problem.context_graph), len(base_problem.context_graph) // n_eigenvalue)\n",
    "    t = torch.zeros(mc_samples, 2, r.shape[0])\n",
    "    for j_index, j in tqdm(enumerate(r)):\n",
    "        for i in range(mc_samples):\n",
    "            all_X = torch.arange(len(base_problem.context_graph)).to(torch.float)\n",
    "            all_Y = base_model.covar_module.base_kernel.eigenbasis[:,j].detach().clone()\n",
    "            from botorch.utils.transforms import standardize\n",
    "            n_init = len(all_X)\n",
    "            X = all_X.reshape(-1, 1).detach().clone()\n",
    "\n",
    "            # Y = base_problem(X.reshape(-1, 1))\n",
    "            Y = all_Y.reshape(-1, 1).to(dtype=torch.float).detach().clone()\n",
    "            Y = standardize(Y)\n",
    "\n",
    "            best_loc = Y.argmax().item()\n",
    "            X_best = X[best_loc]\n",
    "\n",
    "            n_train = int(n_init * prop_data)\n",
    "            ntrain_indices = np.random.choice(n_init, n_train, replace=False)\n",
    "            ntest_indices = np.array([i for i in range(n_init) if i not in ntrain_indices])\n",
    "            X_train, Y_train = X[ntrain_indices, ...], Y[ntrain_indices]\n",
    "            X_test, Y_test = X[ntest_indices, ...], Y[ntest_indices, ...]\n",
    "            criterion = torch.nn.MSELoss()\n",
    "\n",
    "            order = 5\n",
    "            model_poly, mll_poly, cached_eigenbasis_poly = initialize_model(\n",
    "                        train_X=X_train,\n",
    "                        train_Y=Y_train,\n",
    "                        context_graph=base_problem.context_graph,\n",
    "                        covar_type=\"polynomial\",\n",
    "                        covar_kwargs = {\n",
    "                            \"order\": order,\n",
    "                            },\n",
    "                        fit_model=True,\n",
    "                        ard=True,\n",
    "                        use_fixed_noise=False,\n",
    "                        optim_kwargs = {\n",
    "                            \"train_iters\": 500,\n",
    "                            \"lr\": 0.1\n",
    "                        },\n",
    "                        use_saas_map=False\n",
    "                        )\n",
    "            \n",
    "            model_diff, mll_diff, cached_eigenbasis_diff = initialize_model(\n",
    "                        train_X=X_train,\n",
    "                        train_Y=Y_train,\n",
    "                        context_graph=base_problem.context_graph,\n",
    "                        covar_type=\"polynomial\",\n",
    "                        covar_kwargs = {\n",
    "                            \"order\": len(base_problem.context_graph.nodes),\n",
    "                            },\n",
    "                        fit_model=True,\n",
    "                        ard=True,\n",
    "                        use_fixed_noise=False,\n",
    "                        optim_kwargs = {\n",
    "                            \"train_iters\": 500,\n",
    "                            \"lr\": 0.1\n",
    "                        },\n",
    "                        use_saas_map=False\n",
    "                        )\n",
    "            \n",
    "            model_poly.eval()\n",
    "            with torch.no_grad():\n",
    "                # predict on train input\n",
    "                Y_test_pred = model_poly.posterior(X_test).mean\n",
    "                error = torch.sqrt(criterion(Y_test_pred, Y_test))\n",
    "                #mll_poly(Y_test_pred, Y_test)\n",
    "                t[i, 0, j_index] = error\n",
    "\n",
    "            model_diff.eval()\n",
    "            with torch.no_grad():\n",
    "                # predict on train input\n",
    "                Y_test_pred = model_diff.posterior(X_test).mean\n",
    "                error = torch.sqrt(criterion(Y_test_pred, Y_test))\n",
    "                t[i, 1, j_index] = error\n",
    "    return t\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<class 'networkx.utils.decorators.argmap'> compilation 12:4: FutureWarning: normalized_laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "/home/pierreo/miniconda3/envs/graph/lib/python3.10/site-packages/botorch/models/gpytorch.py:129: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  warnings.warn(_get_single_precision_warning(X.dtype), UserWarning)\n",
      "0it [00:00, ?it/s]/home/pierreo/miniconda3/envs/graph/lib/python3.10/site-packages/botorch/models/utils/assorted.py:173: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "1it [00:31, 31.59s/it]"
     ]
    }
   ],
   "source": [
    "n = 400\n",
    "base_problem = get_synthetic_problem(\n",
    "    \"test_function\", \n",
    "    n=n, \n",
    "    seed=2,\n",
    "    problem_kwargs={\n",
    "        \"log\": False, \n",
    "        \"random_graph_type\": \"grid\",\n",
    "        \"m\": 1,\n",
    "        \"n\": n,\n",
    "        \"test_function\": \"sphere\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "X_train = torch.empty(0,1)\n",
    "Y_train = torch.empty(0,1)\n",
    "base_model, base_mll, based_cached_eigenbasis = initialize_model(\n",
    "                train_X=X_train,\n",
    "                train_Y=Y_train,\n",
    "                context_graph=base_problem.context_graph,\n",
    "                covar_type=\"diffusion\",\n",
    "                covar_kwargs = {\n",
    "                    \"order\": 1,\n",
    "                     },\n",
    "                fit_model=False,\n",
    "                ard=True,\n",
    "                use_fixed_noise=False,\n",
    "                use_saas_map=False\n",
    "                )\n",
    "\n",
    "result = compute_test_result(base_problem, base_model, mc_samples=10, prop_data=0.5, n_eigenvalue=10)\n",
    "result_mean_0, result_std_0 = result.mean(dim=0)[0], result.std(dim=0)[0]  \n",
    "result_mean_1, result_std_1 = result.mean(dim=0)[1], result.std(dim=0)[1]  \n",
    "plt.errorbar(x = range(result_mean_0.shape[0]), y = result_mean_0, yerr= result_std_0, label=\"Poly\")\n",
    "plt.errorbar(x = range(result_mean_1.shape[0]), y = result_mean_1, yerr= result_std_1, label=\"Poly\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 400\n",
    "base_problem = get_synthetic_problem(\n",
    "    \"test_function\", \n",
    "    n=n, \n",
    "    seed=2,\n",
    "    problem_kwargs={\n",
    "        \"log\": False, \n",
    "        \"random_graph_type\": \"ba\",\n",
    "        \"m\": 2,\n",
    "        \"n\": n,\n",
    "        \"test_function\": \"sphere\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "X_train = torch.empty(0,1)\n",
    "Y_train = torch.empty(0,1)\n",
    "base_model, base_mll, based_cached_eigenbasis = initialize_model(\n",
    "                train_X=X_train,\n",
    "                train_Y=Y_train,\n",
    "                context_graph=base_problem.context_graph,\n",
    "                covar_type=\"diffusion\",\n",
    "                covar_kwargs = {\n",
    "                    \"order\": 1,\n",
    "                     },\n",
    "                fit_model=False,\n",
    "                ard=True,\n",
    "                use_fixed_noise=False,\n",
    "                use_saas_map=False\n",
    "                )\n",
    "\n",
    "result = compute_test_result(base_problem, base_model, mc_samples=10, prop_data=0.5, n_eigenvalue=10)\n",
    "result_mean_0, result_std_0 = result.mean(dim=0)[0], result.std(dim=0)[0]  \n",
    "result_mean_1, result_std_1 = result.mean(dim=0)[1], result.std(dim=0)[1]  \n",
    "plt.errorbar(x = range(result_mean_0.shape[0]), y = result_mean_0, yerr= result_std_0, label=\"Poly\")\n",
    "plt.errorbar(x = range(result_mean_1.shape[0]), y = result_mean_1, yerr= result_std_1, label=\"Poly\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 400\n",
    "base_problem = get_synthetic_problem(\n",
    "    \"test_function\", \n",
    "    n=n, \n",
    "    seed=2,\n",
    "    problem_kwargs={\n",
    "        \"log\": False, \n",
    "        \"random_graph_type\": \"ws\",\n",
    "        \"m\": 2,\n",
    "        \"p\": 0.2,\n",
    "        \"k\": 4,\n",
    "        \"test_function\": \"sphere\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "X_train = torch.empty(0,1)\n",
    "Y_train = torch.empty(0,1)\n",
    "base_model, base_mll, based_cached_eigenbasis = initialize_model(\n",
    "                train_X=X_train,\n",
    "                train_Y=Y_train,\n",
    "                context_graph=base_problem.context_graph,\n",
    "                covar_type=\"diffusion\",\n",
    "                covar_kwargs = {\n",
    "                    \"order\": 1,\n",
    "                     },\n",
    "                fit_model=False,\n",
    "                ard=True,\n",
    "                use_fixed_noise=False,\n",
    "                use_saas_map=False\n",
    "                )\n",
    "\n",
    "result = compute_test_result(base_problem, base_model, mc_samples=10, prop_data=0.5, n_eigenvalue=10)\n",
    "result_mean_0, result_std_0 = result.mean(dim=0)[0], result.std(dim=0)[0]  \n",
    "result_mean_1, result_std_1 = result.mean(dim=0)[1], result.std(dim=0)[1]  \n",
    "plt.errorbar(x = range(result_mean_0.shape[0]), y = result_mean_0, yerr= result_std_0, label=\"Poly\")\n",
    "plt.errorbar(x = range(result_mean_1.shape[0]), y = result_mean_1, yerr= result_std_1, label=\"Poly\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
